this week: have these done 

why do they have an accept bias?
can we identify papers that are in the training data?

- test non-instruct models. 

question: why is

test: 
- Parallel Distill Response - n generations. Summarizer across them. 
- 2 Strats: 1) role bad review, 2)

simple prompt + simple prompt fewshot
simple prompt + PDR. Each reduce, look at reduction prompts 

N = 4. Make 3 bias towards reject, 1 positive


q: how to get noise model

p(r|a) = 50%
p(a|r) = 20%

bayesian optimal models.

gemini: just test title. plot against citations

a lot of borderline accept are rejected by other

knowing the noise, can we build noisy labels or find maximum. 