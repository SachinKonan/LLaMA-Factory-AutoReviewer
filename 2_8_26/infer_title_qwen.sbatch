#!/bin/bash
#SBATCH --job-name=title_only_infer
#SBATCH --time=1:00:00
#SBATCH --cpus-per-task=10
#SBATCH --mem=48G
#SBATCH --gres=gpu:1
#SBATCH --array=0-4
#SBATCH --output=2_8_26/logs/title_infer_%A_%a.out
#SBATCH --error=2_8_26/logs/title_infer_%A_%a.err
#SBATCH --comment="Title-Only Contamination Check"

# ============================================================================
# Title-Only Inference: Multiple Qwen Models
# ============================================================================
# Tests whether models can predict accept/reject from paper titles alone.
# Each array index runs a different model on the same title-only dataset.
#
# Models:
#   0: Qwen/Qwen2.5-7B-Instruct     (qwen template)
#   1: Qwen/Qwen2.5-VL-7B-Instruct  (qwen2_vl template)
#   2: Qwen/Qwen3-8B                 (qwen3 template)
#   3: Qwen/Qwen3-4B                 (qwen3 template)
#   4: Qwen/Qwen3-8B-Thinking        (qwen3 template)
#
# Usage:
#   sbatch 2_8_26/infer_title_qwen.sbatch                # all models
#   sbatch --array=0-1 2_8_26/infer_title_qwen.sbatch    # Qwen2.5 only
#   sbatch --array=2-4 2_8_26/infer_title_qwen.sbatch    # Qwen3 only
#   sbatch --array=0 2_8_26/infer_title_qwen.sbatch      # single model test
# ============================================================================

set -e

# Configuration
PROJECT_DIR="/n/fs/vision-mix/jl0796/LLaMA-Factory-AutoReviewer"
cd "${PROJECT_DIR}"
source .vllm/bin/activate

# Create logs and results dirs
mkdir -p 2_8_26/logs
mkdir -p 2_8_26/results

# Data directory (where generate_title_dataset.py writes output)
DATA_DIR="${PROJECT_DIR}/inference_scaling/data"

# Title-only dataset (clean text-only, generated by generate_title_dataset.py)
DATASET="iclr_2020_2025_85_5_10_split7_balanced_clean_binary_noreviews_v7_test_title_only"

# ============================================================================
# Model Configuration
# ============================================================================
MODELS=(
    "Qwen/Qwen2.5-7B-Instruct"
    "Qwen/Qwen2.5-VL-7B-Instruct"
    "Qwen/Qwen3-8B"
    "Qwen/Qwen3-4B"
    "Qwen/Qwen3-8B-Thinking"
)

TEMPLATES=(
    "qwen"
    "qwen2_vl"
    "qwen3"
    "qwen3"
    "qwen3"
)

# Short names for output files
SHORT_NAMES=(
    "qwen2.5_7b_instruct"
    "qwen2.5_vl_7b_instruct"
    "qwen3_8b"
    "qwen3_4b"
    "qwen3_8b_thinking"
)

# Get current model config
MODEL="${MODELS[$SLURM_ARRAY_TASK_ID]}"
TEMPLATE="${TEMPLATES[$SLURM_ARRAY_TASK_ID]}"
SHORT_NAME="${SHORT_NAMES[$SLURM_ARRAY_TASK_ID]}"

# Title-only needs minimal context
CUTOFF_LEN=4096
MAX_NEW_TOKENS=512

# Output file
OUTPUT_FILE="2_8_26/results/${SHORT_NAME}_title_predictions.jsonl"

echo "=============================================="
echo "Job: $SLURM_JOB_ID, Task: $SLURM_ARRAY_TASK_ID"
echo "Model: ${MODEL}"
echo "Template: ${TEMPLATE}"
echo "Dataset: ${DATASET}"
echo "Cutoff Length: ${CUTOFF_LEN}"
echo "Output: ${OUTPUT_FILE}"
echo "=============================================="

# Check if dataset exists
if [ ! -d "${DATA_DIR}/${DATASET}" ]; then
    echo "ERROR: Dataset not found: ${DATA_DIR}/${DATASET}"
    echo "Please run: python 2_8_26/generate_title_dataset.py"
    exit 1
fi

# Build inference command
INFERENCE_CMD="python ablations/run_inference.py \
    --model_name_or_path ${MODEL} \
    --dataset ${DATASET} \
    --dataset_dir ${DATA_DIR} \
    --template ${TEMPLATE} \
    --cutoff_len ${CUTOFF_LEN} \
    --max_new_tokens ${MAX_NEW_TOKENS} \
    --save_name ${OUTPUT_FILE} \
    --n_generations 1"

# Run inference
eval ${INFERENCE_CMD}

echo "=============================================="
echo "Inference complete for ${MODEL}"
echo "Output saved to: ${OUTPUT_FILE}"
echo "=============================================="
