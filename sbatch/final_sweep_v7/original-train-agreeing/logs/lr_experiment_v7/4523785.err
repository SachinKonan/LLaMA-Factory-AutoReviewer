Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
[INFO|hub.py:421] 2026-02-06 09:32:16,568 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:1949] 2026-02-06 09:32:16,582 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file vocab.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file merges.txt from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file tokenizer.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file tokenizer_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,585 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2026-02-06 09:32:16,773 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|hub.py:421] 2026-02-06 09:32:16,773 >> Offline mode: forcing local_files_only=True
[INFO|hub.py:421] 2026-02-06 09:32:16,774 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:316] 2026-02-06 09:32:16,775 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2026-02-06 09:32:16,776 >> loading configuration file preprocessor_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:316] 2026-02-06 09:32:16,783 >> Offline mode: forcing local_files_only=True
[INFO|image_processing_base.py:383] 2026-02-06 09:32:16,784 >> loading configuration file preprocessor_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|image_processing_base.py:428] 2026-02-06 09:32:16,790 >> Image processor Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:1949] 2026-02-06 09:32:16,791 >> Offline mode: forcing local_files_only=True
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,791 >> loading file vocab.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/vocab.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file merges.txt from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/merges.txt
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file tokenizer.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file tokenizer_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2095] 2026-02-06 09:32:16,792 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2364] 2026-02-06 09:32:16,988 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|video_processing_utils.py:660] 2026-02-06 09:32:16,988 >> Offline mode: forcing local_files_only=True
[INFO|video_processing_utils.py:726] 2026-02-06 09:32:16,989 >> loading configuration file video_preprocessor_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/preprocessor_config.json
[INFO|video_processing_utils.py:770] 2026-02-06 09:32:16,993 >> Video processor Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|processing_utils.py:928] 2026-02-06 09:32:16,993 >> Offline mode: forcing local_files_only=True
[INFO|processing_utils.py:1116] 2026-02-06 09:32:16,994 >> loading configuration file processor_config.json from cache at None
[INFO|processing_utils.py:1199] 2026-02-06 09:32:17,338 >> Processor Qwen2_5_VLProcessor:
- image_processor: Qwen2VLImageProcessorFast {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "disable_grouping": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessorFast",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_tensors": null,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-7B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|object_ref_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|object_ref_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|box_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|image_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|video_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)
- video_processor: Qwen2VLVideoProcessor {
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "do_sample_frames": false,
  "fps": null,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_frames": 768,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_frames": 4,
  "min_pixels": 3136,
  "num_frames": null,
  "pad_size": null,
  "patch_size": 14,
  "processor_class": "Qwen2_5_VLProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_metadata": false,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2,
  "video_metadata": null,
  "video_processor_type": "Qwen2VLVideoProcessor"
}


{
  "processor_class": "Qwen2_5_VLProcessor"
}

Converting format of dataset (num_proc=16):   0%|          | 0/11392 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   1%|          | 81/11392 [00:00<00:46, 241.02 examples/s]Converting format of dataset (num_proc=16):  23%|â–ˆâ–ˆâ–Ž       | 2609/11392 [00:00<00:01, 7701.47 examples/s]Converting format of dataset (num_proc=16):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5081/11392 [00:00<00:00, 12773.62 examples/s]Converting format of dataset (num_proc=16):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 7741/11392 [00:00<00:00, 16867.21 examples/s]Converting format of dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 10655/11392 [00:00<00:00, 20119.40 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11392/11392 [00:00<00:00, 13000.65 examples/s]
Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 778 examples [00:00, 35296.58 examples/s]
Converting format of dataset (num_proc=16):   0%|          | 0/778 [00:00<?, ? examples/s]Converting format of dataset (num_proc=16):   6%|â–‹         | 49/778 [00:00<00:04, 179.47 examples/s]Converting format of dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778/778 [00:00<00:00, 1902.00 examples/s]
Running tokenizer on dataset (num_proc=16):   0%|          | 0/11392 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 712/11392 [08:41<2:10:22,  1.37 examples/s]Running tokenizer on dataset (num_proc=16):  12%|â–ˆâ–Ž        | 1424/11392 [08:44<50:28,  3.29 examples/s] Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 2136/11392 [08:44<25:29,  6.05 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 2136/11392 [08:58<25:29,  6.05 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 2848/11392 [09:12<16:27,  8.65 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 3560/11392 [09:17<09:58, 13.09 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 4272/11392 [09:17<06:00, 19.75 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4984/11392 [09:18<03:39, 29.25 examples/s]Running tokenizer on dataset (num_proc=16):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4984/11392 [09:28<03:39, 29.25 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5696/11392 [09:29<02:42, 35.15 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 6408/11392 [09:31<01:41, 48.97 examples/s]Running tokenizer on dataset (num_proc=16):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 6408/11392 [09:48<01:41, 48.97 examples/s]Running tokenizer on dataset (num_proc=16):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 7120/11392 [09:59<01:52, 38.06 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 7832/11392 [10:00<01:06, 53.53 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 9256/11392 [10:01<00:21, 97.92 examples/s]Running tokenizer on dataset (num_proc=16):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 9968/11392 [10:01<00:11, 128.08 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 10680/11392 [10:04<00:04, 151.42 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11392/11392 [10:07<00:00, 162.26 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11392/11392 [10:08<00:00, 18.74 examples/s] 
Running tokenizer on dataset (num_proc=16):   0%|          | 0/778 [00:00<?, ? examples/s]Running tokenizer on dataset (num_proc=16):   6%|â–‹         | 49/778 [00:36<09:09,  1.33 examples/s]Running tokenizer on dataset (num_proc=16):  13%|â–ˆâ–Ž        | 98/778 [00:37<03:32,  3.20 examples/s]Running tokenizer on dataset (num_proc=16):  19%|â–ˆâ–‰        | 147/778 [00:37<01:49,  5.75 examples/s]Running tokenizer on dataset (num_proc=16):  25%|â–ˆâ–ˆâ–Œ       | 196/778 [00:39<01:09,  8.33 examples/s]Running tokenizer on dataset (num_proc=16):  31%|â–ˆâ–ˆâ–ˆâ–      | 245/778 [00:39<00:41, 12.77 examples/s]Running tokenizer on dataset (num_proc=16):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 294/778 [00:39<00:25, 19.04 examples/s]Running tokenizer on dataset (num_proc=16):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 392/778 [00:40<00:11, 34.22 examples/s]Running tokenizer on dataset (num_proc=16):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 441/778 [00:41<00:09, 36.19 examples/s]Running tokenizer on dataset (num_proc=16):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 489/778 [00:41<00:06, 43.88 examples/s]Running tokenizer on dataset (num_proc=16):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 537/778 [00:42<00:04, 56.63 examples/s]Running tokenizer on dataset (num_proc=16):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 633/778 [00:42<00:01, 86.47 examples/s]Running tokenizer on dataset (num_proc=16):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 730/778 [00:42<00:00, 107.51 examples/s]Running tokenizer on dataset (num_proc=16): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 778/778 [00:43<00:00, 18.05 examples/s] 
[INFO|hub.py:421] 2026-02-06 09:43:10,227 >> Offline mode: forcing local_files_only=True
[INFO|configuration_utils.py:765] 2026-02-06 09:43:10,239 >> loading configuration file config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/config.json
[INFO|configuration_utils.py:839] 2026-02-06 09:43:10,244 >> Model config Qwen2_5_VLConfig {
  "architectures": [
    "Qwen2_5_VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "dtype": "bfloat16",
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 3584,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 18944,
  "max_position_embeddings": 128000,
  "max_window_layers": 28,
  "model_type": "qwen2_5_vl",
  "num_attention_heads": 28,
  "num_hidden_layers": 28,
  "num_key_value_heads": 4,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "text_config": {
    "_name_or_path": "Qwen/Qwen2.5-VL-7B-Instruct",
    "architectures": [
      "Qwen2_5_VLForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "bos_token_id": 151643,
    "dtype": "bfloat16",
    "eos_token_id": 151645,
    "hidden_act": "silu",
    "hidden_size": 3584,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "layer_types": [
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention",
      "full_attention"
    ],
    "max_position_embeddings": 128000,
    "max_window_layers": 28,
    "model_type": "qwen2_5_vl_text",
    "num_attention_heads": 28,
    "num_hidden_layers": 28,
    "num_key_value_heads": 4,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "sliding_window": null,
    "use_cache": true,
    "use_sliding_window": false,
    "vision_token_id": 151654,
    "vocab_size": 152064
  },
  "tie_word_embeddings": false,
  "transformers_version": "4.57.1",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "fullatt_block_indexes": [
      7,
      15,
      23,
      31
    ],
    "hidden_act": "silu",
    "hidden_size": 1280,
    "in_channels": 3,
    "in_chans": 3,
    "initializer_range": 0.02,
    "intermediate_size": 3420,
    "model_type": "qwen2_5_vl",
    "num_heads": 16,
    "out_hidden_size": 3584,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "tokens_per_second": 2,
    "window_size": 112
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 152064
}

[INFO|hub.py:421] 2026-02-06 09:43:10,670 >> Offline mode: forcing local_files_only=True
`torch_dtype` is deprecated! Use `dtype` instead!
[WARNING|logging.py:328] 2026-02-06 09:43:10,684 >> `torch_dtype` is deprecated! Use `dtype` instead!
[INFO|hub.py:421] 2026-02-06 09:43:10,684 >> Offline mode: forcing local_files_only=True
[INFO|modeling_utils.py:4837] 2026-02-06 09:43:10,685 >> Offline mode: forcing local_files_only=True
[INFO|modeling_utils.py:1172] 2026-02-06 09:43:10,686 >> loading weights file model.safetensors from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/model.safetensors.index.json
[INFO|modeling_utils.py:1243] 2026-02-06 09:43:10,713 >> Will use dtype=torch.bfloat16 as defined in model's config object
[INFO|modeling_utils.py:2341] 2026-02-06 09:43:10,713 >> Instantiating Qwen2_5_VLForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:986] 2026-02-06 09:43:10,714 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

[INFO|modeling_utils.py:2341] 2026-02-06 09:43:10,724 >> Instantiating Qwen2_5_VLTextModel model under default dtype torch.bfloat16.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:00<00:00, 36.07it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 36.04it/s]
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:04<00:19,  4.99s/it]The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:06<00:08,  2.86s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:07<00:04,  2.19s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:09<00:01,  1.87s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.83s/it]
[INFO|configuration_utils.py:941] 2026-02-06 09:43:19,890 >> loading configuration file generation_config.json from cache at /scratch/gpfs/ZHUANGL/sk7524/hf/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5/generation_config.json
[INFO|configuration_utils.py:986] 2026-02-06 09:43:19,891 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.05,
  "temperature": 1e-06
}

[INFO|dynamic_module_utils.py:423] 2026-02-06 09:43:19,892 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-VL-7B-Instruct.
[INFO|trainer.py:749] 2026-02-06 09:44:11,166 >> Using auto half precision backend
[WARNING|trainer.py:982] 2026-02-06 09:44:11,167 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/accelerate/utils/fsdp_utils.py:710: UserWarning: FSDP upcast of low precision parameters to fp32 (since mixed_precision != 'no') may affect the precision of model checkpoints.
  warnings.warn(
[INFO|trainer.py:2519] 2026-02-06 09:44:18,921 >> ***** Running training *****
[INFO|trainer.py:2520] 2026-02-06 09:44:18,921 >>   Num examples = 11,392
[INFO|trainer.py:2521] 2026-02-06 09:44:18,921 >>   Num Epochs = 6
[INFO|trainer.py:2522] 2026-02-06 09:44:18,921 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:2525] 2026-02-06 09:44:18,921 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:2526] 2026-02-06 09:44:18,921 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2527] 2026-02-06 09:44:18,921 >>   Total optimization steps = 4,272
[INFO|trainer.py:2528] 2026-02-06 09:44:18,922 >>   Number of trainable parameters = 7,615,616,512
  0%|          | 0/4272 [00:00<?, ?it/s][INFO|trainer.py:4643] 2026-02-06 09:44:18,926 >> 
***** Running Evaluation *****
[INFO|trainer.py:4645] 2026-02-06 09:44:18,927 >>   Num examples = 778
[INFO|trainer.py:4648] 2026-02-06 09:44:18,927 >>   Batch size = 2

  0%|          | 0/195 [00:00<?, ?it/s][A
  1%|          | 2/195 [00:04<06:49,  2.12s/it][A
  2%|â–         | 3/195 [00:07<07:54,  2.47s/it][A
  2%|â–         | 4/195 [00:11<09:32,  3.00s/it][A
  3%|â–Ž         | 5/195 [00:14<10:10,  3.21s/it][A
  3%|â–Ž         | 6/195 [00:18<10:33,  3.35s/it][A
  4%|â–Ž         | 7/195 [00:21<10:19,  3.30s/it][A
  4%|â–         | 8/195 [00:25<10:28,  3.36s/it][A
  5%|â–         | 9/195 [00:28<10:15,  3.31s/it][A
  5%|â–Œ         | 10/195 [00:31<10:06,  3.28s/it][A
  6%|â–Œ         | 11/195 [00:35<11:12,  3.65s/it][A
  6%|â–Œ         | 12/195 [00:39<11:14,  3.69s/it][A
  7%|â–‹         | 13/195 [00:43<10:58,  3.62s/it][A
  7%|â–‹         | 14/195 [00:46<10:53,  3.61s/it][A
  8%|â–Š         | 15/195 [00:50<10:32,  3.51s/it][A
  8%|â–Š         | 16/195 [00:53<10:13,  3.43s/it][A
  9%|â–Š         | 17/195 [00:56<09:58,  3.36s/it][A
  9%|â–‰         | 18/195 [00:59<09:53,  3.35s/it][A
 10%|â–‰         | 19/195 [01:03<09:47,  3.34s/it][A
 10%|â–ˆ         | 20/195 [01:06<09:45,  3.35s/it][A
 11%|â–ˆ         | 21/195 [01:09<09:40,  3.34s/it][A
 11%|â–ˆâ–        | 22/195 [01:13<09:49,  3.41s/it][A
 12%|â–ˆâ–        | 23/195 [01:16<09:38,  3.36s/it][A
 12%|â–ˆâ–        | 24/195 [01:19<09:34,  3.36s/it][A
 13%|â–ˆâ–Ž        | 25/195 [01:23<09:28,  3.34s/it][A
 13%|â–ˆâ–Ž        | 26/195 [01:26<09:24,  3.34s/it][A
 14%|â–ˆâ–        | 27/195 [01:29<09:22,  3.35s/it][A
 14%|â–ˆâ–        | 28/195 [01:33<09:39,  3.47s/it][A
 15%|â–ˆâ–        | 29/195 [01:36<09:16,  3.35s/it][A
 15%|â–ˆâ–Œ        | 30/195 [01:40<09:24,  3.42s/it][A
 16%|â–ˆâ–Œ        | 31/195 [01:43<09:12,  3.37s/it][A
 16%|â–ˆâ–‹        | 32/195 [01:46<09:06,  3.35s/it][A
 17%|â–ˆâ–‹        | 33/195 [01:50<09:03,  3.35s/it][A
 17%|â–ˆâ–‹        | 34/195 [01:53<08:55,  3.32s/it][A
 18%|â–ˆâ–Š        | 35/195 [01:56<08:34,  3.21s/it][A
 18%|â–ˆâ–Š        | 36/195 [01:59<08:36,  3.25s/it][A
 19%|â–ˆâ–‰        | 37/195 [02:03<08:36,  3.27s/it][A
 19%|â–ˆâ–‰        | 38/195 [02:07<09:03,  3.46s/it][A
 20%|â–ˆâ–ˆ        | 39/195 [02:10<09:00,  3.46s/it][A
 21%|â–ˆâ–ˆ        | 40/195 [02:14<09:17,  3.60s/it][A
 21%|â–ˆâ–ˆ        | 41/195 [02:18<09:16,  3.61s/it][A
 22%|â–ˆâ–ˆâ–       | 42/195 [02:21<09:13,  3.62s/it][A
 22%|â–ˆâ–ˆâ–       | 43/195 [02:25<09:13,  3.64s/it][A
 23%|â–ˆâ–ˆâ–Ž       | 44/195 [02:29<09:23,  3.73s/it][A
 23%|â–ˆâ–ˆâ–Ž       | 45/195 [02:33<09:18,  3.73s/it][A
 24%|â–ˆâ–ˆâ–Ž       | 46/195 [02:37<09:27,  3.81s/it][A
 24%|â–ˆâ–ˆâ–       | 47/195 [02:40<09:22,  3.80s/it][A
 25%|â–ˆâ–ˆâ–       | 48/195 [02:44<09:28,  3.87s/it][A
 25%|â–ˆâ–ˆâ–Œ       | 49/195 [02:48<09:18,  3.83s/it][A
 26%|â–ˆâ–ˆâ–Œ       | 50/195 [02:52<09:19,  3.86s/it][A
 26%|â–ˆâ–ˆâ–Œ       | 51/195 [02:56<09:13,  3.85s/it][A
 27%|â–ˆâ–ˆâ–‹       | 52/195 [03:00<09:01,  3.79s/it][A
 27%|â–ˆâ–ˆâ–‹       | 53/195 [03:03<08:54,  3.76s/it][A
 28%|â–ˆâ–ˆâ–Š       | 54/195 [03:07<08:59,  3.83s/it][A
 28%|â–ˆâ–ˆâ–Š       | 55/195 [03:11<08:37,  3.70s/it][A
 29%|â–ˆâ–ˆâ–Š       | 56/195 [03:15<08:46,  3.79s/it][A
 29%|â–ˆâ–ˆâ–‰       | 57/195 [03:19<08:48,  3.83s/it][A
 30%|â–ˆâ–ˆâ–‰       | 58/195 [03:23<08:53,  3.90s/it][A
 30%|â–ˆâ–ˆâ–ˆ       | 59/195 [03:26<08:48,  3.89s/it][A
 31%|â–ˆâ–ˆâ–ˆ       | 60/195 [03:30<08:46,  3.90s/it][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 61/195 [03:34<08:41,  3.89s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 62/195 [03:38<08:29,  3.83s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/195 [03:42<08:21,  3.80s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 64/195 [03:46<08:22,  3.83s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/195 [03:49<08:12,  3.79s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 66/195 [03:53<07:56,  3.70s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 67/195 [03:56<07:52,  3.69s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–      | 68/195 [04:00<07:38,  3.61s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 69/195 [04:03<07:29,  3.57s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/195 [04:07<07:28,  3.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 71/195 [04:11<07:27,  3.61s/it][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 72/195 [04:14<07:28,  3.65s/it][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 73/195 [04:18<07:38,  3.75s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 74/195 [04:22<07:20,  3.64s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/195 [04:25<07:09,  3.58s/it][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 76/195 [04:29<07:12,  3.63s/it][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 77/195 [04:33<07:09,  3.64s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 78/195 [04:36<07:05,  3.63s/it][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 79/195 [04:40<07:03,  3.65s/it][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/195 [04:44<07:00,  3.66s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 81/195 [04:47<06:49,  3.59s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 82/195 [04:50<06:37,  3.52s/it][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 83/195 [04:54<06:48,  3.65s/it][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 84/195 [04:58<06:45,  3.65s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/195 [05:02<07:06,  3.87s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 86/195 [05:07<07:13,  3.97s/it][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 87/195 [05:11<07:10,  3.98s/it][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 88/195 [05:14<06:47,  3.81s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 89/195 [05:17<06:29,  3.68s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/195 [05:21<06:33,  3.75s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 91/195 [05:25<06:18,  3.64s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 92/195 [05:28<06:16,  3.65s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 93/195 [05:32<06:04,  3.57s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 94/195 [05:36<06:14,  3.71s/it][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/195 [05:39<06:00,  3.60s/it][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 96/195 [05:43<06:09,  3.73s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 97/195 [05:47<06:13,  3.81s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 98/195 [05:51<06:06,  3.78s/it][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 99/195 [05:55<06:09,  3.84s/it][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 100/195 [05:59<06:07,  3.87s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 101/195 [06:03<06:04,  3.88s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 102/195 [06:06<05:56,  3.83s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 103/195 [06:10<05:39,  3.69s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 104/195 [06:14<05:39,  3.73s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 105/195 [06:17<05:37,  3.75s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 106/195 [06:21<05:42,  3.85s/it][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 107/195 [06:25<05:38,  3.84s/it][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 108/195 [06:30<05:52,  4.05s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 109/195 [06:33<05:37,  3.92s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 110/195 [06:38<05:44,  4.06s/it][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 111/195 [06:42<05:33,  3.98s/it][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 112/195 [06:45<05:25,  3.92s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 113/195 [06:49<05:12,  3.81s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 114/195 [06:53<05:14,  3.88s/it][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 115/195 [06:57<05:08,  3.86s/it][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 116/195 [07:01<05:17,  4.02s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 117/195 [07:05<05:14,  4.04s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 118/195 [07:09<05:12,  4.06s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 119/195 [07:13<05:06,  4.03s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 120/195 [07:17<05:03,  4.05s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 121/195 [07:21<04:45,  3.86s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 122/195 [07:25<04:56,  4.06s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 123/195 [07:30<05:01,  4.19s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 124/195 [07:34<04:55,  4.16s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 125/195 [07:38<04:53,  4.19s/it][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 126/195 [07:42<04:43,  4.11s/it][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 127/195 [07:46<04:45,  4.20s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 128/195 [07:51<04:39,  4.17s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 129/195 [07:55<04:45,  4.33s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 130/195 [07:59<04:32,  4.19s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 131/195 [08:04<04:32,  4.26s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 132/195 [08:08<04:25,  4.21s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 133/195 [08:12<04:21,  4.21s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 134/195 [08:16<04:09,  4.09s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 135/195 [08:20<04:07,  4.12s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 136/195 [08:24<04:10,  4.25s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 137/195 [08:29<04:06,  4.24s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 138/195 [08:33<03:56,  4.15s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 139/195 [08:37<03:50,  4.12s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 140/195 [08:41<03:48,  4.15s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 141/195 [08:45<03:48,  4.23s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 142/195 [08:49<03:36,  4.09s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 143/195 [08:53<03:27,  3.99s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/195 [08:57<03:20,  3.94s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 145/195 [09:01<03:19,  3.98s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 146/195 [09:05<03:17,  4.03s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 147/195 [09:09<03:13,  4.04s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 148/195 [09:13<03:15,  4.16s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 149/195 [09:18<03:19,  4.33s/it][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 150/195 [09:22<03:11,  4.25s/it][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 151/195 [09:27<03:09,  4.32s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 152/195 [09:30<02:59,  4.17s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 153/195 [09:35<02:54,  4.16s/it][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 154/195 [09:39<02:53,  4.23s/it][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 155/195 [09:43<02:51,  4.29s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 156/195 [09:47<02:41,  4.14s/it][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 157/195 [09:52<02:40,  4.23s/it][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 158/195 [09:56<02:38,  4.28s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 159/195 [10:00<02:33,  4.26s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 160/195 [10:05<02:30,  4.31s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 161/195 [10:09<02:27,  4.33s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 162/195 [10:13<02:20,  4.27s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 163/195 [10:17<02:12,  4.15s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/195 [10:21<02:08,  4.13s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 165/195 [10:26<02:07,  4.25s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 166/195 [10:29<01:59,  4.11s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 167/195 [10:33<01:53,  4.04s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 168/195 [10:38<01:52,  4.15s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 169/195 [10:42<01:48,  4.16s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 170/195 [10:46<01:43,  4.13s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 171/195 [10:50<01:36,  4.04s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 172/195 [10:54<01:33,  4.06s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 173/195 [10:57<01:25,  3.90s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 174/195 [11:02<01:23,  3.96s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 175/195 [11:05<01:19,  3.96s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 176/195 [11:10<01:16,  4.02s/it][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 177/195 [11:14<01:13,  4.09s/it][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 178/195 [11:18<01:09,  4.06s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 179/195 [11:22<01:05,  4.08s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 180/195 [11:26<01:00,  4.01s/it][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 181/195 [11:30<00:56,  4.07s/it][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 182/195 [11:34<00:53,  4.15s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/195 [11:39<00:49,  4.15s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/195 [11:43<00:46,  4.21s/it][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 185/195 [11:47<00:41,  4.20s/it][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 186/195 [11:51<00:37,  4.16s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 187/195 [11:56<00:33,  4.22s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 188/195 [11:59<00:28,  4.05s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 189/195 [12:04<00:24,  4.14s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 190/195 [12:08<00:20,  4.16s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 191/195 [12:12<00:16,  4.15s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 192/195 [12:15<00:11,  3.95s/it][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 193/195 [12:19<00:07,  3.89s/it][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 194/195 [12:23<00:04,  4.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [12:27<00:00,  4.03s/it][A                                        
                                                 [A  0%|          | 0/4272 [12:34<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [12:27<00:00,  4.03s/it][A
                                                 [A  0%|          | 1/4272 [13:21<950:18:18, 801.01s/it]  0%|          | 2/4272 [14:01<419:21:37, 353.56s/it]  0%|          | 3/4272 [14:41<249:40:09, 210.54s/it]  0%|          | 4/4272 [15:24<170:56:17, 144.18s/it][rank1]: Traceback (most recent call last):
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/train.py", line 28, in <module>
[rank1]:     main()
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/train.py", line 19, in main
[rank1]:     run_exp()
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/llamafactory/train/tuner.py", line 132, in run_exp
[rank1]:     _training_function(config={"args": args, "callbacks": callbacks})
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/llamafactory/train/tuner.py", line 89, in _training_function
[rank1]:     run_sft(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/llamafactory/train/sft/workflow.py", line 134, in run_sft
[rank1]:     train_result = trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2325, in train
[rank1]:     return inner_training_loop(
[rank1]:            ^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
[rank1]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank1]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 4020, in training_step
[rank1]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/src/llamafactory/train/sft/trainer.py", line 146, in compute_loss
[rank1]:     outputs = super().compute_loss(model, inputs, return_outputs=True, **kwargs)
[rank1]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/trainer.py", line 4110, in compute_loss
[rank1]:     outputs = model(**inputs)
[rank1]:               ^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1857, in _call_impl
[rank1]:     return inner()
[rank1]:            ^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1805, in inner
[rank1]:     result = forward_call(*args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/utils/generic.py", line 918, in wrapper
[rank1]:     output = func(self, *args, **kwargs)
[rank1]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/models/qwen2_5_vl/modeling_qwen2_5_vl.py", line 1503, in forward
[rank1]:     loss = self.loss_function(
[rank1]:            ^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/loss/loss_utils.py", line 67, in ForCausalLMLoss
[rank1]:     loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/transformers/loss/loss_utils.py", line 36, in fixed_cross_entropy
[rank1]:     loss = nn.functional.cross_entropy(source, target, ignore_index=ignore_index, reduction=reduction)
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]:   File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/nn/functional.py", line 3494, in cross_entropy
[rank1]:     return torch._C._nn.cross_entropy_loss(
[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank1]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.07 GiB. GPU 1 has a total capacity of 139.80 GiB of which 15.66 GiB is free. Including non-PyTorch memory, this process has 124.12 GiB memory in use. Of the allocated memory 103.77 GiB is allocated by PyTorch, and 18.38 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
W0206 10:00:23.126000 3860597 torch/distributed/elastic/multiprocessing/api.py:900] Sending process 3860738 closing signal SIGTERM
E0206 10:00:23.147000 3860597 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 1 (pid: 3860739) of binary: /scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/bin/python3
Traceback (most recent call last):
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/bin/accelerate", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/distributed/run.py", line 883, in run
    elastic_launch(
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 139, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/gpfs/ZHUANGL/sk7524/LLaMA-Factory-AutoReviewer/.venv/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 270, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
src/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-06_10:00:23
  host      : della-i23g1
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 3860739)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
